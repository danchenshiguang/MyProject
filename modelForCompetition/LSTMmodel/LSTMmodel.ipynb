{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_2444\\1507552022.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mpandas\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0malgorithms\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mmode\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0msklearn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpreprocessing\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mLabelEncoder\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mMinMaxScaler\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 9\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackend\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mconcatenate\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     10\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0msklearn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmetrics\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mmean_squared_error\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcallbacks\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mHistory\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from numpy import  concatenate\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.core.algorithms import mode\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from tensorflow.python.keras.backend import concatenate\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.python.keras.callbacks import History\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Embedding, LSTM,Dropout\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "path=os.path.abspath('.')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "os.chdir(\"D:\\学习材料\\数学\\数学建模与实验\\美赛\\美赛进行时\\\\2023\\\\2023_MCM-ICM_Problems\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "df=pd.read_excel(\"c.xlsx\",parse_dates=[\"Date\"],index_col=[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "            Contest number   Word  Number of  reported results  \\\nDate                                                             \n2022-01-07             202  slump                        80630   \n2022-01-08             203  crank                       101503   \n2022-01-09             204  gorge                        91477   \n2022-01-10             205  query                       107134   \n2022-01-11             206  drink                       153880   \n\n            Number in hard mode  1 try  2 tries  3 tries  4 tries  5 tries  \\\nDate                                                                         \n2022-01-07                 1362      1        3       23       39       24   \n2022-01-08                 1763      1        5       23       31       24   \n2022-01-09                 1913      1        3       13       27       30   \n2022-01-10                 2242      1        4       16       30       30   \n2022-01-11                 3017      1        9       35       34       16   \n\n            6 tries  ...        q         r         s    t         u    v  \\\nDate                 ...                                                    \n2022-01-07        9  ...  0.00000  0.000000  0.126405  0.0  0.152782  0.0   \n2022-01-08       14  ...  0.00000  0.088472  0.000000  0.0  0.000000  0.0   \n2022-01-09       22  ...  0.00000  0.088472  0.000000  0.0  0.000000  0.0   \n2022-01-10       17  ...  0.35563  0.088472  0.000000  0.0  0.152782  0.0   \n2022-01-11        5  ...  0.00000  0.088472  0.000000  0.0  0.000000  0.0   \n\n              w    x         y    z  \nDate                                 \n2022-01-07  0.0  0.0  0.000000  0.0  \n2022-01-08  0.0  0.0  0.000000  0.0  \n2022-01-09  0.0  0.0  0.000000  0.0  \n2022-01-10  0.0  0.0  0.154195  0.0  \n2022-01-11  0.0  0.0  0.000000  0.0  \n\n[5 rows x 42 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Contest number</th>\n      <th>Word</th>\n      <th>Number of  reported results</th>\n      <th>Number in hard mode</th>\n      <th>1 try</th>\n      <th>2 tries</th>\n      <th>3 tries</th>\n      <th>4 tries</th>\n      <th>5 tries</th>\n      <th>6 tries</th>\n      <th>...</th>\n      <th>q</th>\n      <th>r</th>\n      <th>s</th>\n      <th>t</th>\n      <th>u</th>\n      <th>v</th>\n      <th>w</th>\n      <th>x</th>\n      <th>y</th>\n      <th>z</th>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2022-01-07</th>\n      <td>202</td>\n      <td>slump</td>\n      <td>80630</td>\n      <td>1362</td>\n      <td>1</td>\n      <td>3</td>\n      <td>23</td>\n      <td>39</td>\n      <td>24</td>\n      <td>9</td>\n      <td>...</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.126405</td>\n      <td>0.0</td>\n      <td>0.152782</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2022-01-08</th>\n      <td>203</td>\n      <td>crank</td>\n      <td>101503</td>\n      <td>1763</td>\n      <td>1</td>\n      <td>5</td>\n      <td>23</td>\n      <td>31</td>\n      <td>24</td>\n      <td>14</td>\n      <td>...</td>\n      <td>0.00000</td>\n      <td>0.088472</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2022-01-09</th>\n      <td>204</td>\n      <td>gorge</td>\n      <td>91477</td>\n      <td>1913</td>\n      <td>1</td>\n      <td>3</td>\n      <td>13</td>\n      <td>27</td>\n      <td>30</td>\n      <td>22</td>\n      <td>...</td>\n      <td>0.00000</td>\n      <td>0.088472</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2022-01-10</th>\n      <td>205</td>\n      <td>query</td>\n      <td>107134</td>\n      <td>2242</td>\n      <td>1</td>\n      <td>4</td>\n      <td>16</td>\n      <td>30</td>\n      <td>30</td>\n      <td>17</td>\n      <td>...</td>\n      <td>0.35563</td>\n      <td>0.088472</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.152782</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.154195</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2022-01-11</th>\n      <td>206</td>\n      <td>drink</td>\n      <td>153880</td>\n      <td>3017</td>\n      <td>1</td>\n      <td>9</td>\n      <td>35</td>\n      <td>34</td>\n      <td>16</td>\n      <td>5</td>\n      <td>...</td>\n      <td>0.00000</td>\n      <td>0.088472</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 42 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "test_split=round(len(df)*0.20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "(359, 42)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "df_for_training=df[:-72]\n",
    "df_for_testing=df[-72:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "df=pd.read_excel(\"c_test.xlsx\",parse_dates=[\"Date\"],index_col=[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "\n",
    "from pandas import concat\n",
    "#数据有监督化——————归一化\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    " \"\"\"\n",
    " Frame a time series as a supervised learning dataset.\n",
    " Arguments:\n",
    " data: Sequence of observations as a list or NumPy array.\n",
    " n_in: Number of lag observations as input (X).\n",
    " n_out: Number of observations as output (y).\n",
    " dropnan: Boolean whether or not to drop rows with NaN values.\n",
    " Returns:\n",
    " Pandas DataFrame of series framed for supervised learning.\n",
    " \"\"\"\n",
    " n_vars = 1 if type(data) is list else data.shape[1]\n",
    " df = DataFrame(data)\n",
    " cols, names = list(), list()\n",
    " # input sequence (t-n, ... t-1)\n",
    " for i in range(n_in, 0, -1):\n",
    "    cols.append(df.shift(i))\n",
    "    names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    " # forecast sequence (t, t+1, ... t+n)\n",
    " for i in range(0, n_out):\n",
    "    cols.append(df.shift(-i))\n",
    "    if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "    else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    " # put it all together\n",
    " agg = concat(cols, axis=1)\n",
    " agg.columns = names\n",
    " # drop rows with NaN values\n",
    " if dropnan:\n",
    "    agg.dropna(inplace=True)\n",
    " return agg"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "            1 try  2 tries  3 tries  4 tries  5 tries  6 tries  \\\nDate                                                             \n2022-01-07      1        3       23       39       24        9   \n2022-01-08      1        5       23       31       24       14   \n2022-01-09      1        3       13       27       30       22   \n2022-01-10      1        4       16       30       30       17   \n2022-01-11      1        9       35       34       16        5   \n...           ...      ...      ...      ...      ...      ...   \n2022-12-27      0        2       17       35       29       14   \n2022-12-28      0        3       21       40       25        9   \n2022-12-29      0        2       16       38       30       12   \n2022-12-30      0        4       21       38       26        9   \n2022-12-31      0        2       17       37       29       12   \n\n            7 or more tries (X)  is_repetitive  Grade Level  Word Rank  ...  \\\nDate                                                                    ...   \n2022-01-07                    1              0            3         15  ...   \n2022-01-08                    2              0            1          7  ...   \n2022-01-09                    4              1            1          5  ...   \n2022-01-10                    2              0            1          8  ...   \n2022-01-11                    1              0            1          0  ...   \n...                         ...            ...          ...        ...  ...   \n2022-12-27                    3              1            4        100  ...   \n2022-12-28                    1              0            1          5  ...   \n2022-12-29                    2              0            1          7  ...   \n2022-12-30                    1              0            3         16  ...   \n2022-12-31                    2              0            1          9  ...   \n\n                  q         r         s    t         u         v    w    x  \\\nDate                                                                         \n2022-01-07  0.00000  0.000000  0.126405  0.0  0.152782  0.000000  0.0  0.0   \n2022-01-08  0.00000  0.088472  0.000000  0.0  0.000000  0.000000  0.0  0.0   \n2022-01-09  0.00000  0.088472  0.000000  0.0  0.000000  0.000000  0.0  0.0   \n2022-01-10  0.35563  0.088472  0.000000  0.0  0.152782  0.000000  0.0  0.0   \n2022-01-11  0.00000  0.088472  0.000000  0.0  0.000000  0.000000  0.0  0.0   \n...             ...       ...       ...  ...       ...       ...  ...  ...   \n2022-12-27  0.00000  0.000000  0.000000  0.0  0.000000  0.000000  0.0  0.0   \n2022-12-28  0.00000  0.000000  0.000000  0.0  0.000000  0.000000  0.0  0.0   \n2022-12-29  0.00000  0.000000  0.000000  0.0  0.000000  0.231672  0.0  0.0   \n2022-12-30  0.00000  0.088472  0.000000  0.0  0.000000  0.000000  0.0  0.0   \n2022-12-31  0.00000  0.000000  0.000000  0.0  0.000000  0.000000  0.0  0.0   \n\n                   y    z  \nDate                       \n2022-01-07  0.000000  0.0  \n2022-01-08  0.000000  0.0  \n2022-01-09  0.000000  0.0  \n2022-01-10  0.154195  0.0  \n2022-01-11  0.000000  0.0  \n...              ...  ...  \n2022-12-27  0.000000  0.0  \n2022-12-28  0.000000  0.0  \n2022-12-29  0.000000  0.0  \n2022-12-30  0.000000  0.0  \n2022-12-31  0.154195  0.0  \n\n[359 rows x 37 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1 try</th>\n      <th>2 tries</th>\n      <th>3 tries</th>\n      <th>4 tries</th>\n      <th>5 tries</th>\n      <th>6 tries</th>\n      <th>7 or more tries (X)</th>\n      <th>is_repetitive</th>\n      <th>Grade Level</th>\n      <th>Word Rank</th>\n      <th>...</th>\n      <th>q</th>\n      <th>r</th>\n      <th>s</th>\n      <th>t</th>\n      <th>u</th>\n      <th>v</th>\n      <th>w</th>\n      <th>x</th>\n      <th>y</th>\n      <th>z</th>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2022-01-07</th>\n      <td>1</td>\n      <td>3</td>\n      <td>23</td>\n      <td>39</td>\n      <td>24</td>\n      <td>9</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>15</td>\n      <td>...</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.126405</td>\n      <td>0.0</td>\n      <td>0.152782</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2022-01-08</th>\n      <td>1</td>\n      <td>5</td>\n      <td>23</td>\n      <td>31</td>\n      <td>24</td>\n      <td>14</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>7</td>\n      <td>...</td>\n      <td>0.00000</td>\n      <td>0.088472</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2022-01-09</th>\n      <td>1</td>\n      <td>3</td>\n      <td>13</td>\n      <td>27</td>\n      <td>30</td>\n      <td>22</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>5</td>\n      <td>...</td>\n      <td>0.00000</td>\n      <td>0.088472</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2022-01-10</th>\n      <td>1</td>\n      <td>4</td>\n      <td>16</td>\n      <td>30</td>\n      <td>30</td>\n      <td>17</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>8</td>\n      <td>...</td>\n      <td>0.35563</td>\n      <td>0.088472</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.152782</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.154195</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2022-01-11</th>\n      <td>1</td>\n      <td>9</td>\n      <td>35</td>\n      <td>34</td>\n      <td>16</td>\n      <td>5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.00000</td>\n      <td>0.088472</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2022-12-27</th>\n      <td>0</td>\n      <td>2</td>\n      <td>17</td>\n      <td>35</td>\n      <td>29</td>\n      <td>14</td>\n      <td>3</td>\n      <td>1</td>\n      <td>4</td>\n      <td>100</td>\n      <td>...</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2022-12-28</th>\n      <td>0</td>\n      <td>3</td>\n      <td>21</td>\n      <td>40</td>\n      <td>25</td>\n      <td>9</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>5</td>\n      <td>...</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2022-12-29</th>\n      <td>0</td>\n      <td>2</td>\n      <td>16</td>\n      <td>38</td>\n      <td>30</td>\n      <td>12</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>7</td>\n      <td>...</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.231672</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2022-12-30</th>\n      <td>0</td>\n      <td>4</td>\n      <td>21</td>\n      <td>38</td>\n      <td>26</td>\n      <td>9</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>16</td>\n      <td>...</td>\n      <td>0.00000</td>\n      <td>0.088472</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2022-12-31</th>\n      <td>0</td>\n      <td>2</td>\n      <td>17</td>\n      <td>37</td>\n      <td>29</td>\n      <td>12</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>9</td>\n      <td>...</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.154195</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>359 rows × 37 columns</p>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "#将数据\n",
    "values= df.values\n",
    "values=values.astype('float32')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   var1(t-1)  var2(t-1)  var3(t-1)  var4(t-1)  var5(t-1)  var6(t-1)  \\\n",
      "1   0.166667   0.115385   0.441860   0.736842   0.428571   0.200000   \n",
      "2   0.166667   0.192308   0.441860   0.526316   0.428571   0.342857   \n",
      "3   0.166667   0.115385   0.209302   0.421053   0.600000   0.571429   \n",
      "4   0.166667   0.153846   0.279070   0.500000   0.600000   0.428571   \n",
      "5   0.166667   0.346154   0.720930   0.605263   0.200000   0.085714   \n",
      "\n",
      "   var7(t-1)  var8(t-1)  var9(t-1)  var10(t-1)  ...  var35(t-1)  var36(t-1)  \\\n",
      "1   0.020833        0.0   0.666667        0.15  ...         0.0         0.0   \n",
      "2   0.041667        0.0   0.000000        0.07  ...         0.0         0.0   \n",
      "3   0.083333        1.0   0.000000        0.05  ...         0.0         0.0   \n",
      "4   0.041667        0.0   0.000000        0.08  ...         0.0         0.5   \n",
      "5   0.020833        0.0   0.000000        0.00  ...         0.0         0.0   \n",
      "\n",
      "   var37(t-1)   var1(t)   var2(t)   var3(t)   var4(t)   var5(t)   var6(t)  \\\n",
      "1         0.0  0.166667  0.192308  0.441860  0.526316  0.428571  0.342857   \n",
      "2         0.0  0.166667  0.115385  0.209302  0.421053  0.600000  0.571429   \n",
      "3         0.0  0.166667  0.153846  0.279070  0.500000  0.600000  0.428571   \n",
      "4         0.0  0.166667  0.346154  0.720930  0.605263  0.200000  0.085714   \n",
      "5         0.0  0.166667  0.153846  0.255814  0.394737  0.571429  0.542857   \n",
      "\n",
      "    var7(t)  \n",
      "1  0.041667  \n",
      "2  0.083333  \n",
      "3  0.041667  \n",
      "4  0.020833  \n",
      "5  0.083333  \n",
      "\n",
      "[5 rows x 44 columns]\n"
     ]
    }
   ],
   "source": [
    "#标准化特征\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "scaled=scaler.fit_transform(values)\n",
    "reframed=series_to_supervised(scaled,1,1)\n",
    "reframed.drop(reframed.columns[range(44,74)],axis=1,inplace=True)\n",
    "print(reframed.head())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.        , 0.1923077 , 0.5813954 , ..., 0.54285717, 0.42857143,\n        0.0625    ],\n       [0.        , 0.15384616, 0.32558137, ..., 0.2857143 , 0.11428572,\n        0.02083333],\n       [0.        , 0.26923078, 0.6511628 , ..., 0.5142857 , 1.        ,\n        0.375     ],\n       ...,\n       [0.        , 0.11538462, 0.39534885, ..., 0.6       , 0.2857143 ,\n        0.04166667],\n       [0.        , 0.07692308, 0.27906978, ..., 0.4857143 , 0.20000002,\n        0.02083333],\n       [0.        , 0.15384616, 0.39534885, ..., 0.57142854, 0.2857143 ,\n        0.04166667]], dtype=float32)"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#构建训练集和测试集,选最后72天作为测试集\n",
    "reframed_values=reframed.values\n",
    "train_data=reframed_values[:-72]\n",
    "test_data=reframed_values[-72:]\n",
    "train_data_x,train_data_y=train_data[:,:-7],train_data[:,-7:]\n",
    "test_data_x,test_data_y=test_data[:,:-7],test_data[:,-7:]\n",
    "test_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "#将训练集和测试集重构成LSTM预期的形式\n",
    "train_data_x_input=train_data_x.reshape((train_data_x.shape[0],1,train_data_x.shape[1]))\n",
    "test_data_x_input=test_data_x.reshape((test_data_x.shape[0],1,test_data_x.shape[1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "4/4 - 3s - loss: 0.3110 - val_loss: 0.2938 - 3s/epoch - 766ms/step\n",
      "Epoch 2/60\n",
      "4/4 - 0s - loss: 0.2843 - val_loss: 0.2692 - 37ms/epoch - 9ms/step\n",
      "Epoch 3/60\n",
      "4/4 - 0s - loss: 0.2595 - val_loss: 0.2454 - 38ms/epoch - 10ms/step\n",
      "Epoch 4/60\n",
      "4/4 - 0s - loss: 0.2350 - val_loss: 0.2230 - 42ms/epoch - 10ms/step\n",
      "Epoch 5/60\n",
      "4/4 - 0s - loss: 0.2121 - val_loss: 0.2022 - 43ms/epoch - 11ms/step\n",
      "Epoch 6/60\n",
      "4/4 - 0s - loss: 0.1914 - val_loss: 0.1830 - 38ms/epoch - 10ms/step\n",
      "Epoch 7/60\n",
      "4/4 - 0s - loss: 0.1708 - val_loss: 0.1656 - 37ms/epoch - 9ms/step\n",
      "Epoch 8/60\n",
      "4/4 - 0s - loss: 0.1540 - val_loss: 0.1513 - 37ms/epoch - 9ms/step\n",
      "Epoch 9/60\n",
      "4/4 - 0s - loss: 0.1404 - val_loss: 0.1403 - 38ms/epoch - 9ms/step\n",
      "Epoch 10/60\n",
      "4/4 - 0s - loss: 0.1299 - val_loss: 0.1319 - 34ms/epoch - 9ms/step\n",
      "Epoch 11/60\n",
      "4/4 - 0s - loss: 0.1237 - val_loss: 0.1267 - 36ms/epoch - 9ms/step\n",
      "Epoch 12/60\n",
      "4/4 - 0s - loss: 0.1209 - val_loss: 0.1240 - 36ms/epoch - 9ms/step\n",
      "Epoch 13/60\n",
      "4/4 - 0s - loss: 0.1193 - val_loss: 0.1223 - 35ms/epoch - 9ms/step\n",
      "Epoch 14/60\n",
      "4/4 - 0s - loss: 0.1196 - val_loss: 0.1209 - 35ms/epoch - 9ms/step\n",
      "Epoch 15/60\n",
      "4/4 - 0s - loss: 0.1196 - val_loss: 0.1192 - 34ms/epoch - 9ms/step\n",
      "Epoch 16/60\n",
      "4/4 - 0s - loss: 0.1173 - val_loss: 0.1176 - 36ms/epoch - 9ms/step\n",
      "Epoch 17/60\n",
      "4/4 - 0s - loss: 0.1157 - val_loss: 0.1166 - 35ms/epoch - 9ms/step\n",
      "Epoch 18/60\n",
      "4/4 - 0s - loss: 0.1140 - val_loss: 0.1164 - 36ms/epoch - 9ms/step\n",
      "Epoch 19/60\n",
      "4/4 - 0s - loss: 0.1150 - val_loss: 0.1166 - 35ms/epoch - 9ms/step\n",
      "Epoch 20/60\n",
      "4/4 - 0s - loss: 0.1138 - val_loss: 0.1166 - 38ms/epoch - 9ms/step\n",
      "Epoch 21/60\n",
      "4/4 - 0s - loss: 0.1139 - val_loss: 0.1164 - 37ms/epoch - 9ms/step\n",
      "Epoch 22/60\n",
      "4/4 - 0s - loss: 0.1129 - val_loss: 0.1164 - 35ms/epoch - 9ms/step\n",
      "Epoch 23/60\n",
      "4/4 - 0s - loss: 0.1139 - val_loss: 0.1168 - 37ms/epoch - 9ms/step\n",
      "Epoch 24/60\n",
      "4/4 - 0s - loss: 0.1133 - val_loss: 0.1175 - 35ms/epoch - 9ms/step\n",
      "Epoch 25/60\n",
      "4/4 - 0s - loss: 0.1107 - val_loss: 0.1177 - 37ms/epoch - 9ms/step\n",
      "Epoch 26/60\n",
      "4/4 - 0s - loss: 0.1115 - val_loss: 0.1175 - 36ms/epoch - 9ms/step\n",
      "Epoch 27/60\n",
      "4/4 - 0s - loss: 0.1108 - val_loss: 0.1173 - 38ms/epoch - 10ms/step\n",
      "Epoch 28/60\n",
      "4/4 - 0s - loss: 0.1112 - val_loss: 0.1173 - 37ms/epoch - 9ms/step\n",
      "Epoch 29/60\n",
      "4/4 - 0s - loss: 0.1112 - val_loss: 0.1175 - 37ms/epoch - 9ms/step\n",
      "Epoch 30/60\n",
      "4/4 - 0s - loss: 0.1092 - val_loss: 0.1172 - 37ms/epoch - 9ms/step\n",
      "Epoch 31/60\n",
      "4/4 - 0s - loss: 0.1109 - val_loss: 0.1166 - 34ms/epoch - 9ms/step\n",
      "Epoch 32/60\n",
      "4/4 - 0s - loss: 0.1094 - val_loss: 0.1165 - 38ms/epoch - 9ms/step\n",
      "Epoch 33/60\n",
      "4/4 - 0s - loss: 0.1089 - val_loss: 0.1162 - 36ms/epoch - 9ms/step\n",
      "Epoch 34/60\n",
      "4/4 - 0s - loss: 0.1085 - val_loss: 0.1160 - 33ms/epoch - 8ms/step\n",
      "Epoch 35/60\n",
      "4/4 - 0s - loss: 0.1087 - val_loss: 0.1161 - 51ms/epoch - 13ms/step\n",
      "Epoch 36/60\n",
      "4/4 - 0s - loss: 0.1079 - val_loss: 0.1164 - 42ms/epoch - 11ms/step\n",
      "Epoch 37/60\n",
      "4/4 - 0s - loss: 0.1092 - val_loss: 0.1165 - 41ms/epoch - 10ms/step\n",
      "Epoch 38/60\n",
      "4/4 - 0s - loss: 0.1087 - val_loss: 0.1168 - 41ms/epoch - 10ms/step\n",
      "Epoch 39/60\n",
      "4/4 - 0s - loss: 0.1074 - val_loss: 0.1168 - 40ms/epoch - 10ms/step\n",
      "Epoch 40/60\n",
      "4/4 - 0s - loss: 0.1074 - val_loss: 0.1166 - 46ms/epoch - 11ms/step\n",
      "Epoch 41/60\n",
      "4/4 - 0s - loss: 0.1077 - val_loss: 0.1164 - 40ms/epoch - 10ms/step\n",
      "Epoch 42/60\n",
      "4/4 - 0s - loss: 0.1096 - val_loss: 0.1162 - 112ms/epoch - 28ms/step\n",
      "Epoch 43/60\n",
      "4/4 - 0s - loss: 0.1076 - val_loss: 0.1161 - 122ms/epoch - 31ms/step\n",
      "Epoch 44/60\n",
      "4/4 - 0s - loss: 0.1081 - val_loss: 0.1161 - 46ms/epoch - 12ms/step\n",
      "Epoch 45/60\n",
      "4/4 - 0s - loss: 0.1072 - val_loss: 0.1165 - 41ms/epoch - 10ms/step\n",
      "Epoch 46/60\n",
      "4/4 - 0s - loss: 0.1074 - val_loss: 0.1169 - 40ms/epoch - 10ms/step\n",
      "Epoch 47/60\n",
      "4/4 - 0s - loss: 0.1065 - val_loss: 0.1171 - 37ms/epoch - 9ms/step\n",
      "Epoch 48/60\n",
      "4/4 - 0s - loss: 0.1062 - val_loss: 0.1171 - 37ms/epoch - 9ms/step\n",
      "Epoch 49/60\n",
      "4/4 - 0s - loss: 0.1073 - val_loss: 0.1171 - 38ms/epoch - 9ms/step\n",
      "Epoch 50/60\n",
      "4/4 - 0s - loss: 0.1065 - val_loss: 0.1170 - 37ms/epoch - 9ms/step\n",
      "Epoch 51/60\n",
      "4/4 - 0s - loss: 0.1067 - val_loss: 0.1170 - 37ms/epoch - 9ms/step\n",
      "Epoch 52/60\n",
      "4/4 - 0s - loss: 0.1063 - val_loss: 0.1170 - 36ms/epoch - 9ms/step\n",
      "Epoch 53/60\n",
      "4/4 - 0s - loss: 0.1052 - val_loss: 0.1170 - 36ms/epoch - 9ms/step\n",
      "Epoch 54/60\n",
      "4/4 - 0s - loss: 0.1059 - val_loss: 0.1172 - 34ms/epoch - 8ms/step\n",
      "Epoch 55/60\n",
      "4/4 - 0s - loss: 0.1048 - val_loss: 0.1171 - 35ms/epoch - 9ms/step\n",
      "Epoch 56/60\n",
      "4/4 - 0s - loss: 0.1055 - val_loss: 0.1169 - 34ms/epoch - 8ms/step\n",
      "Epoch 57/60\n",
      "4/4 - 0s - loss: 0.1056 - val_loss: 0.1169 - 36ms/epoch - 9ms/step\n",
      "Epoch 58/60\n",
      "4/4 - 0s - loss: 0.1056 - val_loss: 0.1172 - 36ms/epoch - 9ms/step\n",
      "Epoch 59/60\n",
      "4/4 - 0s - loss: 0.1065 - val_loss: 0.1171 - 33ms/epoch - 8ms/step\n",
      "Epoch 60/60\n",
      "4/4 - 0s - loss: 0.1057 - val_loss: 0.1170 - 36ms/epoch - 9ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#设计神经网络\n",
    "LSTMmodel=Sequential()\n",
    "LSTMmodel.add(LSTM(60,input_shape=(train_data_x_input.shape[1],train_data_x_input.shape[2])))\n",
    "LSTMmodel.add(Dropout(0.1))\n",
    "LSTMmodel.add(Dense(7))\n",
    "LSTMmodel.compile(loss='mae',optimizer='adam')\n",
    "loss_log=LSTMmodel.fit(train_data_x_input,train_data_y,epochs=60,batch_size=72,validation_data=(test_data_x_input,test_data_y),verbose=2, shuffle=False,)\n",
    "plt.plot(loss_log.history['loss'],label='train')\n",
    "plt.plot(loss_log.history['val_loss'],label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "def lstm_predict(model, test_x,test_y):\n",
    "    test_x_out = test_x\n",
    "    test_y_out = test_y\n",
    "    #做出预测\n",
    "    yhat = model.predict(test_x_out)\n",
    "    #将测试集上的预测值还原为原来的数据维度\n",
    "    scale_new = MinMaxScaler()\n",
    "    scale_new.min_, scale_new.scale_ = scaler.min_[0], scaler.scale_[0]\n",
    "    inv_yhat = scale_new.inverse_transform(yhat)\n",
    "    #将测试集上的实际值还原为原来的数据维度\n",
    "    inv_y = scale_new.inverse_transform(test_y_out)\n",
    "    return inv_yhat, inv_y\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "import numpy as np\n",
    "# 计算每一步预测的RMSE\n",
    "def evaluate_forecasts(test, forecasts, n_out):\n",
    "    rmse_dic = {}\n",
    "    for i in range(n_out):\n",
    "        actual = [float(row[i]) for row in test]\n",
    "        predicted = [float(forecast[i]) for forecast in forecasts]\n",
    "        rmse = sqrt(mean_squared_error(actual, predicted))\n",
    "        rmse_dic['t+' + str(i+1) + ' RMSE'] = rmse\n",
    "    return rmse_dic\n",
    "# b=[[0,2,17,37,29,12,2]]\n",
    "# start = np.concatenate((b,test_data_x_input[0,:]), axis=1)\n",
    "# print(start)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step\n",
      "[[-0.02312194  0.88074595  2.3089945   3.6039069   2.9074013   1.5207522\n",
      "   0.33677927]\n",
      " [ 0.29050267  1.1356548   2.378053    3.314426    2.598024    1.2569628\n",
      "   0.20474043]\n",
      " [ 0.07500547  1.1217321   2.6651487   3.9922614   2.5030925   1.4435039\n",
      "   0.24194331]\n",
      " [ 0.46028882  1.0430464   1.9696088   2.7977314   2.3394167   1.5705578\n",
      "   0.35274422]\n",
      " [ 0.08015025  0.85431117  1.8886114   3.2820535   2.5133672   1.6441258\n",
      "   0.2992616 ]\n",
      " [ 0.39429298  1.2170331   2.6703787   3.4012601   2.2829103   1.0306728\n",
      "   0.18512121]\n",
      " [-0.07383908  0.8450919   1.9134401   3.3756723   2.4221642   1.6400061\n",
      "   0.31827405]\n",
      " [ 0.45313895  1.294589    2.4490132   3.1958659   2.8851295   1.7465795\n",
      "   0.30873615]\n",
      " [ 0.2369822   1.1377723   2.5175326   3.7392592   3.0337195   1.738144\n",
      "   0.2521888 ]\n",
      " [-0.07037686  0.65918165  2.3218453   3.5860977   2.8759224   1.8938321\n",
      "   0.35904902]\n",
      " [ 0.26547253  0.9547513   2.0256078   2.909499    2.3653219   1.3066417\n",
      "   0.21591431]\n",
      " [ 0.32480997  1.2047349   2.5050964   3.459479    2.166367    1.1817766\n",
      "   0.211725  ]\n",
      " [ 0.22704792  1.2263979   2.9487813   4.049358    2.485821    1.1169817\n",
      "   0.13564146]\n",
      " [ 0.10173194  1.1718757   2.7370358   3.9738252   2.5240672   1.3689455\n",
      "   0.18287848]\n",
      " [ 0.18088971  0.8276952   2.1306853   3.0319493   2.6474702   1.8117769\n",
      "   0.28698546]\n",
      " [ 0.09987354  1.1232208   2.2845004   3.312071    2.3544066   1.6267556\n",
      "   0.22773185]\n",
      " [ 0.9095843   0.9657136   2.3489819   3.151435    2.7407563   2.0117133\n",
      "   0.4488312 ]\n",
      " [ 0.48470998  1.1293433   2.5315034   3.474791    2.4685519   1.5248646\n",
      "   0.2606262 ]\n",
      " [ 0.04129856  1.1014348   2.9606903   3.8369796   2.478502    1.1001867\n",
      "   0.14898399]\n",
      " [ 0.28380072  0.9770894   2.2726753   3.5882952   2.7355516   1.8479327\n",
      "   0.31435698]\n",
      " [ 0.24413824  1.1713536   2.4999704   3.392022    2.6803508   1.6944585\n",
      "   0.2967212 ]\n",
      " [ 0.10277752  1.0234927   2.43986     3.5385292   2.4859438   1.3771342\n",
      "   0.20310676]\n",
      " [ 0.12893023  0.7922595   2.1809227   3.458594    2.944484    1.7878716\n",
      "   0.3263645 ]\n",
      " [ 0.1374963   0.9208982   2.2292292   3.384026    2.5347297   1.3971459\n",
      "   0.1994796 ]\n",
      " [ 0.19851042  1.3104872   2.8453944   3.950688    2.884085    1.8061087\n",
      "   0.28061378]\n",
      " [ 0.39510253  1.0430282   2.4955723   3.686845    2.6333966   1.6119804\n",
      "   0.264322  ]\n",
      " [ 0.38673207  1.2417232   2.5757694   3.524849    2.9772532   1.7114301\n",
      "   0.28377524]\n",
      " [ 0.22026247  0.87469774  2.3571541   3.3192704   2.9995005   1.8440617\n",
      "   0.2557958 ]\n",
      " [ 0.13071957  0.9986228   2.0938022   3.5087316   2.7052436   1.7566609\n",
      "   0.25607148]\n",
      " [ 0.27487046  1.314068    2.7120368   3.7616203   1.968731    0.779041\n",
      "   0.19842911]\n",
      " [ 0.25722352  1.010882    2.2552304   3.2592766   2.6320915   1.438002\n",
      "   0.20462431]\n",
      " [ 0.3762715   1.0031483   2.4091215   3.2395942   2.623948    1.5382504\n",
      "   0.28033286]\n",
      " [ 0.13870463  1.0434555   2.4009478   3.3340597   2.6120732   1.4508401\n",
      "   0.26863798]\n",
      " [ 0.29988724  0.98429495  2.299891    3.5981019   2.7929885   1.6617391\n",
      "   0.32795906]\n",
      " [ 0.09983274  0.7382428   1.9139948   3.118737    2.8389742   1.7702816\n",
      "   0.32866836]\n",
      " [ 0.92670095  1.2362884   2.8577528   3.6794229   2.3908174   1.5832229\n",
      "   0.34384796]\n",
      " [ 0.05581746  1.3081651   2.763334    3.6788545   2.0753922   0.82760936\n",
      "   0.10493296]\n",
      " [ 0.25615582  1.2731035   2.5886045   3.9679751   2.7771769   1.68988\n",
      "   0.22509854]\n",
      " [ 0.38662678  1.215992    2.5259783   3.3799498   2.1798875   1.4730874\n",
      "   0.16133891]\n",
      " [-0.00625406  0.7999045   2.1490452   3.3739753   2.513364    1.5366023\n",
      "   0.24822003]\n",
      " [ 0.2556121   0.9304396   2.1776676   3.2013674   2.7202206   1.684645\n",
      "   0.26514748]\n",
      " [ 0.18939793  0.901775    2.073604    2.779752    2.2769723   1.2154065\n",
      "   0.21062392]\n",
      " [ 0.14399396  1.0147742   3.106553    4.3587294   2.1826994   1.0184001\n",
      "   0.10831835]\n",
      " [ 0.15951575  1.2427447   2.679469    4.1415133   2.626151    1.4413706\n",
      "   0.18102394]\n",
      " [ 0.20459336  1.2203676   2.350374    3.1355956   2.691785    1.7737424\n",
      "   0.27818924]\n",
      " [ 0.43080005  0.9395802   2.4013116   3.2604532   2.961172    1.9762158\n",
      "   0.312526  ]\n",
      " [ 0.21642786  1.0565839   2.6552618   3.7216394   2.916186    1.6185187\n",
      "   0.1697318 ]\n",
      " [ 0.24066992  0.9485411   2.5282874   3.43817     2.788519    1.5875405\n",
      "   0.28314984]\n",
      " [-0.05958623  1.0157708   2.8006163   3.7171462   1.675316    0.82983863\n",
      "   0.17458735]\n",
      " [ 0.04839442  0.9318054   2.5333836   3.9915361   3.1269417   1.7511263\n",
      "   0.2677923 ]\n",
      " [-0.04057839  0.80346876  2.0823376   3.0589485   2.7219243   1.8260934\n",
      "   0.37691966]\n",
      " [ 0.17417738  1.0190061   2.0838203   3.4685886   3.3629901   2.2254725\n",
      "   0.33724263]\n",
      " [ 0.4630969   1.4147263   2.8501859   3.8183262   2.4111664   1.3033293\n",
      "   0.17113356]\n",
      " [ 0.41155618  1.1122851   2.3261733   3.2818043   2.3897696   1.734876\n",
      "   0.24529183]\n",
      " [ 0.16646746  0.9650844   2.2758794   3.543625    2.8471372   1.7120458\n",
      "   0.27410552]\n",
      " [ 0.36362898  1.0925335   2.5912936   3.2802625   2.549707    1.4571635\n",
      "   0.2633275 ]\n",
      " [ 0.06851632  0.9176535   2.2285244   3.2888885   2.8032603   1.6539814\n",
      "   0.2778031 ]\n",
      " [ 0.20532627  1.04933     2.2702358   3.345898    2.7104237   1.8796985\n",
      "   0.28520083]\n",
      " [ 0.03802334  1.0299779   2.1197684   3.2745187   2.8185015   1.7051944\n",
      "   0.28203285]\n",
      " [ 0.35750762  1.1150358   2.3963766   3.4311182   2.6312156   1.5309548\n",
      "   0.18284687]\n",
      " [ 0.97299635  1.2179418   2.7089145   3.3763485   2.235649    1.6351036\n",
      "   0.36142975]\n",
      " [ 0.00623616  0.7990246   1.8397927   2.9622467   2.586582    1.7286717\n",
      "   0.3432147 ]\n",
      " [ 0.17245853  1.080798    2.2637322   3.3239224   2.7948523   1.7151482\n",
      "   0.27248597]\n",
      " [ 0.25528553  1.0319654   2.4914398   3.7846193   2.7776942   1.5764501\n",
      "   0.21503752]\n",
      " [ 0.39598238  1.2990533   2.4707966   3.2373872   2.700474    1.8385398\n",
      "   0.31982768]\n",
      " [ 0.33992726  1.17218     2.648034    3.7152565   2.5449014   1.5282887\n",
      "   0.2891098 ]\n",
      " [ 0.41876042  1.0429323   2.4298797   3.283589    2.6318774   1.4028457\n",
      "   0.19692588]\n",
      " [ 0.10485455  0.88265675  2.6176543   3.5712626   1.8096306   0.8029472\n",
      "   0.16036849]\n",
      " [ 0.2686861   1.3364872   2.5919065   3.5042498   2.845615    1.6930966\n",
      "   0.28898987]\n",
      " [ 0.06907892  0.8580973   2.3773928   3.81741     2.7333114   1.5215564\n",
      "   0.26665738]\n",
      " [ 0.2746821   1.3308672   2.8678832   3.6516862   2.511092    1.129352\n",
      "   0.12270563]\n",
      " [ 0.25296074  1.0599705   2.4745474   3.4756575   2.8823004   1.7657444\n",
      "   0.3154254 ]]\n"
     ]
    }
   ],
   "source": [
    "inv_yhat=lstm_predict(LSTMmodel,test_data_x_input,test_data_y)[0]\n",
    "\n",
    "print(inv_yhat)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 1. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "    var1(t-1)  var2(t-1)  var3(t-1)  var4(t-1)  var5(t-1)  var6(t-1)  \\\n",
      "1         0.0        1.0        1.0        1.0        1.0        1.0   \n",
      "2         0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "3         0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "4         0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "5         0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "6         0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "7         0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "8         0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "9         0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "10        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "11        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "12        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "13        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "14        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "15        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "16        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "17        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "18        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "19        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "20        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "21        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "22        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "23        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "24        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "25        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "26        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "27        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "28        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "29        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "30        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "31        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "32        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "33        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "34        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "35        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "36        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "37        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "38        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "39        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "40        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "41        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "42        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "43        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "44        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "45        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "46        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "47        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "48        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "49        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "50        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "51        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "52        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "53        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "54        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "55        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "56        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "57        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "58        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "59        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "60        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "\n",
      "    var7(t-1)  var8(t-1)  var9(t-1)  var10(t-1)  ...  var28(t)  var29(t)  \\\n",
      "1         1.0        0.0   0.000000        0.09  ...       0.0       1.0   \n",
      "2         0.0        0.0   0.000000        0.15  ...       0.0       0.0   \n",
      "3         0.0        0.0   1.000000        0.05  ...       0.0       0.0   \n",
      "4         0.0        0.0   0.000000        0.00  ...       0.0       1.0   \n",
      "5         0.0        0.0   0.000000        1.00  ...       0.0       1.0   \n",
      "6         0.0        1.0   0.000000        0.00  ...       0.0       0.0   \n",
      "7         0.0        0.0   0.000000        0.07  ...       0.0       0.0   \n",
      "8         0.0        1.0   0.000000        0.07  ...       0.0       0.0   \n",
      "9         0.0        0.0   1.000000        0.00  ...       0.0       0.0   \n",
      "10        0.0        1.0   0.000000        0.15  ...       0.0       0.0   \n",
      "11        0.0        0.0   0.000000        1.00  ...       0.0       0.0   \n",
      "12        0.0        1.0   0.000000        0.00  ...       0.0       1.0   \n",
      "13        0.0        0.0   0.000000        0.05  ...       0.0       0.0   \n",
      "14        0.0        0.0   1.000000        0.05  ...       0.0       0.0   \n",
      "15        0.0        0.0   0.000000        0.11  ...       0.0       0.0   \n",
      "16        0.0        1.0   0.000000        0.13  ...       0.0       1.0   \n",
      "17        0.0        0.0   0.000000        0.05  ...       0.0       0.0   \n",
      "18        0.0        0.0   0.000000        0.01  ...       0.0       0.0   \n",
      "19        0.0        0.0   0.333333        0.15  ...       0.0       0.0   \n",
      "20        0.0        1.0   0.333333        0.00  ...       0.0       0.0   \n",
      "21        0.0        1.0   0.000000        0.15  ...       0.0       0.0   \n",
      "22        0.0        0.0   0.000000        0.01  ...       0.0       0.0   \n",
      "23        0.0        1.0   0.000000        0.11  ...       0.0       1.0   \n",
      "24        0.0        0.0   0.000000        0.05  ...       0.0       0.0   \n",
      "25        0.0        0.0   1.000000        0.19  ...       0.0       0.0   \n",
      "26        0.0        0.0   1.000000        0.06  ...       0.0       0.0   \n",
      "27        0.0        1.0   0.000000        0.05  ...       0.0       0.0   \n",
      "28        0.0        0.0   0.333333        1.00  ...       0.0       0.0   \n",
      "29        0.0        0.0   0.000000        0.16  ...       0.0       0.0   \n",
      "30        0.0        1.0   0.000000        0.00  ...       0.0       0.0   \n",
      "31        0.0        1.0   0.000000        0.06  ...       0.0       0.0   \n",
      "32        0.0        0.0   0.666667        0.00  ...       0.0       0.0   \n",
      "33        0.0        1.0   1.000000        1.00  ...       0.0       0.0   \n",
      "34        0.0        1.0   0.000000        0.09  ...       0.0       0.0   \n",
      "35        0.0        0.0   0.000000        0.07  ...       0.0       1.0   \n",
      "36        0.0        0.0   0.000000        0.00  ...       0.0       0.0   \n",
      "37        0.0        0.0   0.000000        0.03  ...       0.0       0.0   \n",
      "38        0.0        1.0   0.333333        0.19  ...       0.0       0.0   \n",
      "39        0.0        0.0   0.333333        1.00  ...       0.0       0.0   \n",
      "40        0.0        1.0   0.000000        0.03  ...       0.0       1.0   \n",
      "41        0.0        1.0   0.000000        0.08  ...       0.0       1.0   \n",
      "42        0.0        0.0   0.000000        0.02  ...       0.0       1.0   \n",
      "43        0.0        0.0   0.000000        0.08  ...       0.0       1.0   \n",
      "44        0.0        0.0   0.666667        0.05  ...       0.0       0.0   \n",
      "45        0.0        0.0   0.000000        0.10  ...       0.0       0.0   \n",
      "46        0.0        0.0   1.000000        0.00  ...       0.0       0.0   \n",
      "47        0.0        0.0   0.666667        0.10  ...       0.0       0.0   \n",
      "48        0.0        1.0   1.000000        0.00  ...       0.0       0.0   \n",
      "49        0.0        0.0   0.000000        0.00  ...       0.0       0.0   \n",
      "50        0.0        0.0   0.333333        0.02  ...       0.0       0.0   \n",
      "51        0.0        1.0   0.000000        0.03  ...       0.0       0.0   \n",
      "52        0.0        0.0   0.000000        1.00  ...       0.0       0.0   \n",
      "53        0.0        0.0   1.000000        0.08  ...       0.0       0.0   \n",
      "54        0.0        0.0   0.666667        0.16  ...       0.0       0.0   \n",
      "55        0.0        0.0   0.000000        0.01  ...       0.0       0.0   \n",
      "56        0.0        0.0   0.000000        1.00  ...       0.0       1.0   \n",
      "57        0.0        0.0   0.000000        0.05  ...       0.0       1.0   \n",
      "58        0.0        0.0   1.000000        0.06  ...       0.0       1.0   \n",
      "59        0.0        0.0   0.000000        0.07  ...       0.0       0.0   \n",
      "60        0.0        0.0   0.000000        0.01  ...       0.0       1.0   \n",
      "\n",
      "    var30(t)  var31(t)  var32(t)  var33(t)  var34(t)  var35(t)  var36(t)  \\\n",
      "1        1.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "2        0.0       1.0       0.0       0.0       0.0       0.0       1.0   \n",
      "3        0.0       1.0       1.0       0.0       0.0       0.0       0.0   \n",
      "4        0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "5        0.0       1.0       1.0       0.0       0.0       0.0       0.0   \n",
      "6        0.0       0.0       0.0       0.0       1.0       0.0       0.0   \n",
      "7        0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "8        1.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "9        0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "10       0.0       0.0       0.0       0.0       1.0       0.0       0.0   \n",
      "11       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "12       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "13       1.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "14       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "15       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "16       1.0       0.0       1.0       0.0       0.0       0.0       0.0   \n",
      "17       1.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "18       0.0       0.0       1.0       0.0       1.0       0.0       0.0   \n",
      "19       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "20       0.0       0.0       1.0       0.0       0.0       0.0       0.0   \n",
      "21       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "22       1.0       0.0       1.0       0.0       0.0       0.0       0.0   \n",
      "23       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "24       1.0       0.0       0.0       0.0       0.0       0.0       1.0   \n",
      "25       0.0       0.0       1.0       0.0       0.0       0.0       0.0   \n",
      "26       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "27       1.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "28       0.0       0.0       0.0       1.0       0.0       0.0       1.0   \n",
      "29       0.0       0.0       0.0       0.0       1.0       0.0       0.0   \n",
      "30       1.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "31       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "32       0.0       0.0       1.0       0.0       0.0       0.0       0.0   \n",
      "33       1.0       1.0       0.0       0.0       1.0       0.0       0.0   \n",
      "34       0.0       1.0       0.0       0.0       0.0       0.0       0.0   \n",
      "35       1.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "36       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "37       0.0       1.0       1.0       0.0       0.0       0.0       0.0   \n",
      "38       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "39       0.0       0.0       0.0       0.0       0.0       0.0       1.0   \n",
      "40       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "41       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "42       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "43       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "44       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "45       1.0       1.0       1.0       0.0       0.0       0.0       0.0   \n",
      "46       0.0       0.0       0.0       0.0       0.0       0.0       1.0   \n",
      "47       0.0       1.0       0.0       0.0       0.0       0.0       1.0   \n",
      "48       0.0       1.0       0.0       0.0       1.0       0.0       0.0   \n",
      "49       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "50       0.0       1.0       0.0       0.0       0.0       0.0       0.0   \n",
      "51       0.0       0.0       1.0       0.0       0.0       0.0       0.0   \n",
      "52       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "53       0.0       1.0       0.0       0.0       0.0       0.0       0.0   \n",
      "54       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "55       0.0       1.0       0.0       0.0       0.0       0.0       0.0   \n",
      "56       1.0       0.0       1.0       0.0       1.0       0.0       0.0   \n",
      "57       0.0       1.0       0.0       0.0       0.0       0.0       0.0   \n",
      "58       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "59       0.0       1.0       0.0       0.0       0.0       0.0       0.0   \n",
      "60       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "\n",
      "    var37(t)  \n",
      "1        0.0  \n",
      "2        0.0  \n",
      "3        0.0  \n",
      "4        0.0  \n",
      "5        0.0  \n",
      "6        1.0  \n",
      "7        0.0  \n",
      "8        0.0  \n",
      "9        0.0  \n",
      "10       0.0  \n",
      "11       0.0  \n",
      "12       0.0  \n",
      "13       0.0  \n",
      "14       0.0  \n",
      "15       0.0  \n",
      "16       0.0  \n",
      "17       0.0  \n",
      "18       0.0  \n",
      "19       0.0  \n",
      "20       0.0  \n",
      "21       0.0  \n",
      "22       0.0  \n",
      "23       0.0  \n",
      "24       0.0  \n",
      "25       0.0  \n",
      "26       0.0  \n",
      "27       0.0  \n",
      "28       0.0  \n",
      "29       0.0  \n",
      "30       0.0  \n",
      "31       0.0  \n",
      "32       0.0  \n",
      "33       0.0  \n",
      "34       0.0  \n",
      "35       0.0  \n",
      "36       0.0  \n",
      "37       0.0  \n",
      "38       0.0  \n",
      "39       0.0  \n",
      "40       0.0  \n",
      "41       0.0  \n",
      "42       0.0  \n",
      "43       0.0  \n",
      "44       0.0  \n",
      "45       0.0  \n",
      "46       0.0  \n",
      "47       0.0  \n",
      "48       0.0  \n",
      "49       0.0  \n",
      "50       0.0  \n",
      "51       0.0  \n",
      "52       0.0  \n",
      "53       0.0  \n",
      "54       0.0  \n",
      "55       0.0  \n",
      "56       0.0  \n",
      "57       0.0  \n",
      "58       0.0  \n",
      "59       0.0  \n",
      "60       0.0  \n",
      "\n",
      "[60 rows x 74 columns]\n",
      "2/2 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[ 1.37298554e-01,  3.78117085e-01,  7.67549455e-01,\n         1.12046719e+00,  9.51488733e-01,  6.10187948e-01,\n         1.12563692e-01],\n       [ 2.75427476e-02,  2.33698338e-01,  4.22388315e-01,\n         5.81730604e-01,  3.73606861e-01,  1.55070335e-01,\n         2.83205919e-02],\n       [ 6.33717934e-03,  1.56695858e-01,  3.60892862e-01,\n         5.17929077e-01,  2.78145939e-01,  1.10925287e-01,\n         3.33717093e-02],\n       [-8.74368995e-02,  1.86424196e-01,  3.30513090e-01,\n         4.79955882e-01,  2.39529282e-01,  1.16709851e-01,\n         2.04109401e-02],\n       [ 5.65744266e-02,  1.65965825e-01,  2.25941569e-01,\n         4.87636447e-01,  4.50542748e-01,  3.27725619e-01,\n         3.70280705e-02],\n       [-2.13216990e-02,  2.50393361e-01,  3.76834810e-01,\n         5.90642512e-01,  3.42260569e-01,  1.86508477e-01,\n         3.64806578e-02],\n       [ 2.68166456e-02,  1.01686761e-01,  2.78829783e-01,\n         4.12074357e-01,  2.58536756e-01,  1.21344000e-01,\n         1.79258715e-02],\n       [-6.40764832e-03,  1.36208355e-01,  2.61623889e-01,\n         4.63653386e-01,  3.58883232e-01,  2.46644646e-01,\n         3.28303613e-02],\n       [ 5.27356789e-02,  1.76381007e-01,  3.95364106e-01,\n         5.17483771e-01,  3.26086223e-01,  1.36682227e-01,\n         1.30759296e-03],\n       [ 3.77803147e-02,  2.65978187e-01,  5.32474875e-01,\n         6.36040270e-01,  2.46594995e-01,  9.31634679e-02,\n         2.20735036e-02],\n       [-9.93855298e-02,  1.38674498e-01,  3.98223370e-01,\n         6.85023308e-01,  3.23410273e-01,  2.35540658e-01,\n         1.66509878e-02],\n       [ 6.95398264e-03,  2.08247885e-01,  4.63622600e-01,\n         5.95532894e-01,  2.66757220e-01,  1.47121429e-01,\n         3.71152461e-02],\n       [-2.49147564e-02,  1.90111414e-01,  3.12678605e-01,\n         5.73844850e-01,  4.43786621e-01,  3.21958691e-01,\n         6.56842515e-02],\n       [ 1.72565617e-02,  2.00713739e-01,  4.46741223e-01,\n         5.15675783e-01,  2.67688990e-01,  6.08713925e-02,\n         1.37881236e-02],\n       [-4.80936058e-02,  1.06302157e-01,  3.85331631e-01,\n         6.81500077e-01,  3.88434649e-01,  2.70349294e-01,\n         5.96406348e-02],\n       [-2.81245355e-03,  1.87789366e-01,  3.36711884e-01,\n         6.03556335e-01,  3.21292847e-01,  2.54500955e-01,\n         5.39651662e-02],\n       [ 3.29341739e-04,  2.58590996e-01,  4.76795852e-01,\n         6.58490777e-01,  4.02493328e-01,  1.89646631e-01,\n         3.18599828e-02],\n       [ 9.17479694e-02,  2.49274448e-01,  4.72012758e-01,\n         5.16154051e-01,  3.60142410e-01,  1.37045115e-01,\n         3.11930273e-02],\n       [-5.35705574e-02,  1.35916933e-01,  3.18169445e-01,\n         4.89515692e-01,  2.86702961e-01,  1.89920425e-01,\n         4.17527817e-02],\n       [ 3.13828215e-02,  1.21037498e-01,  2.39080250e-01,\n         3.50834727e-01,  3.18351150e-01,  2.71778107e-01,\n         5.40675819e-02],\n       [-4.21427153e-02,  2.40266949e-01,  4.77529019e-01,\n         6.81393445e-01,  3.67774457e-01,  2.00932175e-01,\n         3.76770161e-02],\n       [-8.05863887e-02,  7.76141435e-02,  2.29814291e-01,\n         5.87529302e-01,  3.86416465e-01,  3.30367446e-01,\n         6.55812100e-02],\n       [-5.83606958e-03,  2.55052209e-01,  5.18815398e-01,\n         6.54480040e-01,  2.85286069e-01,  7.86843151e-02,\n         2.19615307e-02],\n       [ 5.38526177e-02,  2.06505552e-01,  3.87587637e-01,\n         5.01382351e-01,  3.31440508e-01,  2.23384917e-01,\n         4.13956121e-02],\n       [ 6.67925254e-02,  1.94026440e-01,  3.79541159e-01,\n         5.14590144e-01,  4.00347322e-01,  2.17010677e-01,\n         4.10553887e-02],\n       [ 8.50843266e-03,  2.34866425e-01,  3.05050731e-01,\n         4.97063577e-01,  3.70789766e-01,  2.04711020e-01,\n         4.25809324e-02],\n       [ 3.72104272e-02,  1.99920252e-01,  3.90345395e-01,\n         5.08364975e-01,  2.08703548e-01,  1.07021756e-01,\n         3.03775426e-02],\n       [-4.24611643e-02,  2.15154052e-01,  4.23837215e-01,\n         6.22748017e-01,  4.02464628e-01,  2.30615228e-01,\n         3.83402258e-02],\n       [-3.78445685e-02,  1.23637266e-01,  3.10629427e-01,\n         5.98915637e-01,  3.87607664e-01,  2.63921976e-01,\n         5.79884350e-02],\n       [-2.36406550e-03,  1.01728156e-01,  2.06439465e-01,\n         4.29696649e-01,  4.17446524e-01,  3.26372057e-01,\n         5.95272668e-02],\n       [ 3.12074181e-02,  1.81347072e-01,  3.38897139e-01,\n         4.89514083e-01,  3.78593385e-01,  2.79448956e-01,\n         5.52324317e-02],\n       [-4.75820899e-02,  1.39538348e-01,  2.84553558e-01,\n         5.58652759e-01,  3.46240968e-01,  2.27831215e-01,\n         4.78895754e-02],\n       [-5.64175285e-03,  2.55448163e-01,  4.65089709e-01,\n         6.21237636e-01,  2.79075891e-01,  1.64303541e-01,\n         2.99831089e-02],\n       [-4.37587388e-02,  1.89124420e-01,  4.28062439e-01,\n         5.64758062e-01,  3.11477929e-01,  1.45373136e-01,\n         3.51707302e-02],\n       [-7.18092173e-02,  9.85050648e-02,  3.47603649e-01,\n         5.95652759e-01,  3.19446295e-01,  2.53813833e-01,\n         3.78727429e-02],\n       [-1.23162754e-03,  2.01643258e-01,  3.90682995e-01,\n         5.78684151e-01,  4.31041330e-01,  2.32584298e-01,\n         3.98854800e-02],\n       [ 1.50402132e-02,  1.57338575e-01,  2.01540381e-01,\n         3.90127063e-01,  3.23700547e-01,  1.62810415e-01,\n         5.14651835e-02],\n       [-7.08665848e-02,  2.07977042e-01,  4.36119229e-01,\n         6.53200209e-01,  3.20762008e-01,  2.34454870e-01,\n         5.98425381e-02],\n       [-1.40379723e-02,  2.46703401e-01,  5.48325479e-01,\n         6.62994564e-01,  2.38167644e-01,  8.15623775e-02,\n         9.47126746e-03],\n       [ 8.31789970e-02,  2.01130956e-01,  4.11646336e-01,\n         5.15105009e-01,  2.22693712e-01,  1.20323785e-01,\n         3.61488909e-02],\n       [ 1.75687280e-02,  2.26852432e-01,  3.24135900e-01,\n         5.35483956e-01,  3.72553170e-01,  2.63625175e-01,\n         3.71788181e-02],\n       [ 9.40447580e-03,  1.50863498e-01,  2.97709018e-01,\n         4.09777015e-01,  2.98348337e-01,  1.70667142e-01,\n         3.69737670e-02],\n       [ 2.00474858e-02,  1.31493092e-01,  2.10417122e-01,\n         4.22044694e-01,  4.93591279e-01,  3.63299400e-01,\n         5.95000796e-02],\n       [ 3.40620242e-02,  1.93766847e-01,  3.90460610e-01,\n         4.76541847e-01,  3.10526907e-01,  2.04982281e-01,\n         3.28235030e-02],\n       [ 4.37521599e-02,  2.72563100e-01,  4.56224680e-01,\n         5.69310248e-01,  2.48459548e-01,  7.78570324e-02,\n         8.24353937e-03],\n       [-3.98413576e-02,  3.32367271e-01,  5.62636971e-01,\n         6.83867991e-01,  2.95580775e-01,  8.54119360e-02,\n         2.18393710e-02],\n       [ 9.82448459e-02,  2.25507751e-01,  5.01140594e-01,\n         5.06116271e-01,  1.99777484e-01,  2.01981775e-02,\n         2.72895042e-02],\n       [ 1.80248637e-02,  1.54590964e-01,  3.47343415e-01,\n         5.19148946e-01,  2.71981031e-01,  1.55508786e-01,\n         3.99228521e-02],\n       [-7.38844424e-02,  1.10881358e-01,  3.00589770e-01,\n         4.61264759e-01,  2.71326989e-01,  1.34743020e-01,\n         2.53239535e-02],\n       [ 5.46459369e-02,  2.43112117e-01,  4.07924950e-01,\n         5.39668679e-01,  3.72450888e-01,  2.01190382e-01,\n         3.43102999e-02],\n       [-6.15970753e-02,  1.60599142e-01,  2.56375939e-01,\n         5.59755683e-01,  3.91489089e-01,  2.86129922e-01,\n         5.46202399e-02],\n       [-5.63030727e-02,  2.15964869e-01,  3.92690957e-01,\n         5.81973910e-01,  3.44909072e-01,  1.81011975e-01,\n         3.29425707e-02],\n       [ 7.29694366e-02,  1.56433523e-01,  3.00020248e-01,\n         5.16413212e-01,  3.45594734e-01,  1.71872616e-01,\n         3.97651270e-02],\n       [-7.41811097e-02,  2.67483920e-01,  4.30049956e-01,\n         7.35225320e-01,  3.29742104e-01,  1.29791513e-01,\n         2.09669601e-02],\n       [ 2.34022252e-02,  1.73390210e-01,  2.63908058e-01,\n         5.18214107e-01,  4.40262824e-01,  3.32434863e-01,\n         6.77588060e-02],\n       [-6.67228401e-02,  2.02498794e-01,  3.98059607e-01,\n         6.96311474e-01,  3.11836064e-01,  1.64001554e-01,\n         3.65527309e-02],\n       [ 2.61723902e-02,  2.62092233e-01,  4.62647200e-01,\n         5.33048630e-01,  3.54182065e-01,  1.35039479e-01,\n         3.41821872e-02],\n       [-3.19419168e-02,  1.80210754e-01,  3.36855054e-01,\n         5.56841910e-01,  3.77991468e-01,  2.17730671e-01,\n         3.42570171e-02],\n       [-3.80500443e-02,  1.75981492e-01,  3.45436484e-01,\n         7.11559236e-01,  4.89935517e-01,  3.71848345e-01,\n         4.11079973e-02],\n       [-4.71393168e-02,  1.64877504e-01,  2.32810497e-01,\n         4.89956439e-01,  2.32008815e-01,  8.78162682e-02,\n         1.62560623e-02]], dtype=float32)"
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_data=pd.read_excel(\"c_test2.xlsx\",parse_dates=[\"Date\"],index_col=[0])\n",
    "p_data=predict_data[358:]\n",
    "#将数据\n",
    "predict_values= p_data.values\n",
    "predict_values=predict_values.astype('float32')\n",
    "predict_scaled=scaler.fit_transform(predict_values)\n",
    "reframed_1=series_to_supervised(predict_scaled,1,1)\n",
    "reframed_1.drop(reframed_1.columns[range(44,74)],axis=1,inplace=True)\n",
    "reframed_1_values=reframed_1.values\n",
    "predict_data_x,predict_data_y=reframed_1_values[:,:-7],reframed_1_values[:,-7:]\n",
    "predict_data_x_input=predict_data_x.reshape((predict_data_x.shape[0],1,predict_data_x.shape[1]))\n",
    "pre_y=lstm_predict(LSTMmodel,predict_data_x_input,predict_data_y)[0]\n",
    "pre_y\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[3.36708128e-02, 9.27286521e-02, 1.88232243e-01, 2.74781048e-01,\n        2.33341128e-01, 1.49641231e-01, 2.76048873e-02],\n       [1.51137980e-02, 1.28239542e-01, 2.31781214e-01, 3.19218665e-01,\n        2.05012903e-01, 8.50932449e-02, 1.55406324e-02],\n       [4.32779361e-03, 1.07010916e-01, 2.46461362e-01, 3.53704721e-01,\n        1.89951748e-01, 7.57532269e-02, 2.27902457e-02],\n       [0.00000000e+00, 1.35725021e-01, 2.40628093e-01, 3.49429041e-01,\n        1.74387872e-01, 8.49699154e-02, 1.48600638e-02],\n       [3.23021300e-02, 9.47610065e-02, 1.29005179e-01, 2.78424323e-01,\n        2.57245034e-01, 1.87120512e-01, 2.11418066e-02],\n       [0.00000000e+00, 1.40424266e-01, 2.11334482e-01, 3.31240952e-01,\n        1.91944733e-01, 1.04596682e-01, 2.04588864e-02],\n       [2.20311638e-02, 8.35405663e-02, 2.29072079e-01, 3.38538915e-01,\n        2.12400377e-01, 9.96899307e-02, 1.47269657e-02],\n       [0.00000000e+00, 9.08150226e-02, 1.74434081e-01, 3.09134424e-01,\n        2.39280388e-01, 1.64446875e-01, 2.18891855e-02],\n       [3.28358300e-02, 1.09823503e-01, 2.46173173e-01, 3.22210878e-01,\n        2.03037351e-01, 8.51050913e-02, 8.14171799e-04],\n       [2.05987673e-02, 1.45017922e-01, 2.90318549e-01, 3.46784979e-01,\n        1.34449720e-01, 5.07950410e-02, 1.20350234e-02],\n       [0.00000000e+00, 7.71475434e-02, 2.21540064e-01, 3.81092906e-01,\n        1.79919958e-01, 1.31036237e-01, 9.26329568e-03],\n       [4.03047353e-03, 1.20698832e-01, 2.68712014e-01, 3.45166177e-01,\n        1.54610381e-01, 8.52704197e-02, 2.15117037e-02],\n       [0.00000000e+00, 9.96357426e-02, 1.63872138e-01, 3.00747097e-01,\n        2.32584715e-01, 1.68735757e-01, 3.44245471e-02],\n       [1.13326041e-02, 1.31811261e-01, 2.93380648e-01, 3.38650852e-01,\n        1.75794765e-01, 3.99750173e-02, 9.05483682e-03],\n       [0.00000000e+00, 5.61981872e-02, 2.03711197e-01, 3.60284984e-01,\n        2.05351651e-01, 1.42924100e-01, 3.15298922e-02],\n       [0.00000000e+00, 1.06831037e-01, 1.91551208e-01, 3.43355715e-01,\n        1.82779506e-01, 1.44782439e-01, 3.07001118e-02],\n       [1.63185323e-04, 1.28129080e-01, 2.36247256e-01, 3.26275170e-01,\n        1.99431151e-01, 9.39678848e-02, 1.57862809e-02],\n       [4.93914001e-02, 1.34193853e-01, 2.54102290e-01, 2.77865231e-01,\n        1.93878263e-01, 7.37765655e-02, 1.67923849e-02],\n       [0.00000000e+00, 9.29678231e-02, 2.17629403e-01, 3.34831029e-01,\n        1.96106181e-01, 1.29906461e-01, 2.85590999e-02],\n       [2.26340387e-02, 8.72951299e-02, 1.72430366e-01, 2.53030360e-01,\n        2.29602426e-01, 1.96012840e-01, 3.89948264e-02],\n       [0.00000000e+00, 1.19799651e-01, 2.38101035e-01, 3.39749992e-01,\n        1.83376238e-01, 1.00186914e-01, 1.87861603e-02],\n       [0.00000000e+00, 4.62726317e-02, 1.37012556e-01, 3.50277990e-01,\n        2.30376914e-01, 1.96961150e-01, 3.90987396e-02],\n       [0.00000000e+00, 1.40580431e-01, 2.85962224e-01, 3.60738248e-01,\n        1.57244816e-01, 4.33694534e-02, 1.21048214e-02],\n       [3.08513902e-02, 1.18304059e-01, 2.22043380e-01, 2.87234724e-01,\n        1.89877495e-01, 1.27974004e-01, 2.37149503e-02],\n       [3.68334986e-02, 1.06998086e-01, 2.09302291e-01, 2.83776581e-01,\n        2.20776081e-01, 1.19673006e-01, 2.26404611e-02],\n       [5.11455955e-03, 1.41182095e-01, 1.83371037e-01, 2.98793137e-01,\n        2.22887874e-01, 1.23055182e-01, 2.55961027e-02],\n       [2.51092017e-02, 1.34904057e-01, 2.63400912e-01, 3.43039274e-01,\n        1.40830934e-01, 7.22171441e-02, 2.04984434e-02],\n       [0.00000000e+00, 1.11296594e-01, 2.19245881e-01, 3.22140038e-01,\n        2.08190098e-01, 1.19294472e-01, 1.98329352e-02],\n       [0.00000000e+00, 7.09457919e-02, 1.78246036e-01, 3.43671024e-01,\n        2.22417846e-01, 1.51444256e-01, 3.32750455e-02],\n       [0.00000000e+00, 6.60053790e-02, 1.33946344e-01, 2.78804719e-01,\n        2.70856321e-01, 2.11763501e-01, 3.86237204e-02],\n       [1.77897029e-02, 1.03376403e-01, 1.93187386e-01, 2.79046178e-01,\n        2.15816125e-01, 1.59299120e-01, 3.14850956e-02],\n       [0.00000000e+00, 8.69556889e-02, 1.77324370e-01, 3.48133922e-01,\n        2.15765923e-01, 1.41976878e-01, 2.98432000e-02],\n       [0.00000000e+00, 1.40732080e-01, 2.56228298e-01, 3.42253655e-01,\n        1.53749123e-01, 9.05184820e-02, 1.65183637e-02],\n       [0.00000000e+00, 1.12979800e-01, 2.55717427e-01, 3.37377101e-01,\n        1.86071754e-01, 8.68435055e-02, 2.10104119e-02],\n       [0.00000000e+00, 5.95954992e-02, 2.10299984e-01, 3.60369533e-01,\n        1.93264797e-01, 1.53557196e-01, 2.29129847e-02],\n       [0.00000000e+00, 1.07570522e-01, 2.08417445e-01, 3.08710337e-01,\n        2.29947388e-01, 1.24076620e-01, 2.12776866e-02],\n       [1.15514249e-02, 1.20841682e-01, 1.54790252e-01, 2.99631625e-01,\n        2.48613656e-01, 1.25044256e-01, 3.95271108e-02],\n       [0.00000000e+00, 1.08754359e-01, 2.28053376e-01, 3.41568321e-01,\n        1.67731330e-01, 1.22600019e-01, 3.12925726e-02],\n       [0.00000000e+00, 1.38037145e-01, 3.06802750e-01, 3.70963186e-01,\n        1.33261159e-01, 4.56363298e-02, 5.29942708e-03],\n       [5.23063429e-02, 1.26479343e-01, 2.58859992e-01, 3.23919028e-01,\n        1.40038878e-01, 7.56644979e-02, 2.27318965e-02],\n       [9.88452043e-03, 1.27631739e-01, 1.82365388e-01, 3.01274061e-01,\n        2.09605917e-01, 1.48320824e-01, 2.09175516e-02],\n       [6.84587564e-03, 1.09819286e-01, 2.16713727e-01, 2.98292279e-01,\n        2.17179105e-01, 1.24235108e-01, 2.69146115e-02],\n       [1.17899124e-02, 7.73309916e-02, 1.23746157e-01, 2.48204187e-01,\n        2.90280670e-01, 2.13656113e-01, 3.49919535e-02],\n       [2.07295343e-02, 1.17923006e-01, 2.37627283e-01, 2.90014774e-01,\n        1.88981071e-01, 1.24748521e-01, 1.99757926e-02],\n       [2.60987189e-02, 1.62587345e-01, 2.72143811e-01, 3.39600772e-01,\n        1.48209274e-01, 4.64427061e-02, 4.91737574e-03],\n       [0.00000000e+00, 1.67717889e-01, 2.83915699e-01, 3.45090836e-01,\n        1.49154827e-01, 4.31002416e-02, 1.10204993e-02],\n       [6.22482561e-02, 1.42882451e-01, 3.17524344e-01, 3.20676923e-01,\n        1.26579672e-01, 1.27976313e-02, 1.72907189e-02],\n       [1.19645633e-02, 1.02614552e-01, 2.30559975e-01, 3.44601244e-01,\n        1.80535853e-01, 1.03223786e-01, 2.65000332e-02],\n       [0.00000000e+00, 8.50232467e-02, 2.30490670e-01, 3.53695422e-01,\n        2.08052129e-01, 1.03320248e-01, 1.94182768e-02],\n       [2.94856969e-02, 1.31177738e-01, 2.20106959e-01, 2.91192859e-01,\n        2.00965971e-01, 1.08557723e-01, 1.85130518e-02],\n       [0.00000000e+00, 9.39742327e-02, 1.50017813e-01, 3.27539802e-01,\n        2.29078963e-01, 1.67428285e-01, 3.19609120e-02],\n       [0.00000000e+00, 1.23444237e-01, 2.24459812e-01, 3.32652837e-01,\n        1.97147980e-01, 1.03465371e-01, 1.88297778e-02],\n       [4.55185920e-02, 9.75837782e-02, 1.87153682e-01, 3.22140366e-01,\n        2.15583205e-01, 1.07214741e-01, 2.48056259e-02],\n       [0.00000000e+00, 1.39805332e-01, 2.24773422e-01, 3.84278893e-01,\n        1.72345698e-01, 6.78378940e-02, 1.09587628e-02],\n       [1.28628099e-02, 9.53022763e-02, 1.45054549e-01, 2.84831464e-01,\n        2.41986275e-01, 1.82719663e-01, 3.72429825e-02],\n       [0.00000000e+00, 1.11923531e-01, 2.20012352e-01, 3.84859771e-01,\n        1.72355562e-01, 9.06456411e-02, 2.02031359e-02],\n       [1.44809717e-02, 1.45013511e-01, 2.55978972e-01, 2.94931501e-01,\n        1.95966080e-01, 7.47162551e-02, 1.89127289e-02],\n       [0.00000000e+00, 1.05764508e-01, 1.97698012e-01, 3.26806843e-01,\n        2.21840709e-01, 1.27784699e-01, 2.01052185e-02],\n       [0.00000000e+00, 8.23933929e-02, 1.61731109e-01, 3.33147407e-01,\n        2.29384616e-01, 1.74096972e-01, 1.92464963e-02],\n       [0.00000000e+00, 1.34734049e-01, 1.90247312e-01, 4.00380969e-01,\n        1.89592198e-01, 7.17614070e-02, 1.32840751e-02]], dtype=float32)"
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#预测结果重新分配\n",
    "p_y=pre_y\n",
    "p_y[p_y<0]=0\n",
    "p_y_sum_list=[]\n",
    "for i in p_y:\n",
    "    p_y_sum_list.append(sum(i))\n",
    "for i in range(p_y.shape[0]):\n",
    "    for j in range(p_y.shape[1]):\n",
    "        p_y[i][j]=p_y[i][j]/p_y_sum_list[i]\n",
    "p_y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "inv_y=lstm_predict(LSTMmodel,test_data_x_input,test_data_y)[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "(72, 7)"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "{'t+1 RMSE': 1.173433405429987,\n 't+2 RMSE': 1.1015967598962482,\n 't+3 RMSE': 1.2643100639246763,\n 't+4 RMSE': 0.8949316332574658,\n 't+5 RMSE': 1.1016615005717076,\n 't+6 RMSE': 1.1491481293073167,\n 't+7 RMSE': 0.36568252025183}"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_dic=evaluate_forecasts(inv_y,inv_yhat,7)\n",
    "rmse_dic"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}